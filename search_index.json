[
["index.html", "R Reference Sheet for CRSS 8010 Introduction", " R Reference Sheet for CRSS 8010 Jason G. Wallace 2020-09-29 Introduction This is a reference sheet for common uses of R in CRSS 8010, Research Methods &amp; Design in Crop Science. It is not exhaustive, but should cover all the basic function calls you need to analyze our data. Please use the navigation bar at left to go through this site. If you want any of the data files used in the demo code, you can download them from the data directory. This guide was built using the bookdown package for R. "],
["r-basics.html", "Chapter 1 R Basics 1.1 Data types 1.2 Vectors 1.3 Matrices 1.4 Data frames 1.5 Lists 1.6 Reading and writing data 1.7 Boolean expressions 1.8 Other utility functions", " Chapter 1 R Basics This page is for the basic nuts-and-bolts functions that work in R. This is not meant to be comprehensive. If you want in-depth tutorials on R basics, please try: Data Camp - Interactive tutorials Quick-R - Tutorial and basic help guide R for Data Science - Free book on using R for data science 1.1 Data types R has 4 basic data types we deal with: integer - Whole numbers numeric - Decimal numbers logical - True or False character - Character strings We also work with factors, which are a sort of indexed character vector (so “Jane” = 1, “Bert” = 2, etc.) These are most useful when you have something that can take a limited set of values, such as treatments in your experiments. 1.2 Vectors 1.2.1 c() c() (for ‘combine’) is the most basic vector function. It is what you use to make vectors. &gt; # Make a vector of number values &gt; c(1.6, 2.5, 10-0, -9, 14) ## [1] 1.6 2.5 10.0 -9.0 14.0 &gt; &gt; # Make a vector of character strings &gt; c(&quot;Alpha&quot;, &quot;Beta&quot;, &quot;Charlie&quot;, &quot;Delta&quot;) ## [1] &quot;Alpha&quot; &quot;Beta&quot; &quot;Charlie&quot; &quot;Delta&quot; &gt; &gt; # Make a character of logical values &gt; c(TRUE, TRUE, FALSE, FALSE, TRUE) ## [1] TRUE TRUE FALSE FALSE TRUE You can use a colon (“:”) to quickly make a vector consisting of all intergers between two values. &gt; 1:8 ## [1] 1 2 3 4 5 6 7 8 &gt; -2:2 ## [1] -2 -1 0 1 2 1.2.2 length() The length() function tells you how long a vector is &gt; x = c(1,2,3,4,5) &gt; length(x) ## [1] 5 &gt; y = 1:259 &gt; length(y) ## [1] 259 1.2.3 class() The class() function tells you what type of vector you’re working with. &gt; class(1:8) # An integer vector ## [1] &quot;integer&quot; &gt; class(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)) # A character vector ## [1] &quot;character&quot; &gt; class(c(TRUE, FALSE)) # Logical vector ## [1] &quot;logical&quot; It also works on other, more complex data types &gt; # Matrix &gt; m = matrix(1:9, nrow=3) &gt; class(m) ## [1] &quot;matrix&quot; &gt; # Data frame &gt; d = data.frame(a=1:5, b=6:10) &gt; class(d) ## [1] &quot;data.frame&quot; 1.2.4 as.____() The as.____() family of functions will try to force your data into a certain type. If it can’t, it gets set to missing (NA) &gt; x = c(&quot;1.2&quot;, &quot;3&quot;, &quot;Alpha&quot;, &quot;TRUE&quot;, &quot;0&quot;) # A character vector &gt; as.integer(x) ## Warning: NAs introduced by coercion ## [1] 1 3 NA NA 0 &gt; as.numeric(x) ## Warning: NAs introduced by coercion ## [1] 1.2 3.0 NA NA 0.0 &gt; as.logical(x) ## [1] NA NA NA TRUE NA &gt; as.factor(x) ## [1] 1.2 3 Alpha TRUE 0 ## Levels: 0 1.2 3 Alpha TRUE 1.3 Matrices 1.3.1 matrix() You make a matrix by using the matrix() function It requires the data itself and the number of rows and/or columns. &gt; matrix(1:4, nrow=1) # Infer a 1x4 matrix ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 &gt; matrix(1:4, nrow=2) # Infer a 2x2 matrix ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 &gt; matrix(1:4, nrow=2, ncol=4) # Force a 2x4 matrix by recycling the data ## [,1] [,2] [,3] [,4] ## [1,] 1 3 1 3 ## [2,] 2 4 2 4 &gt; matrix(1:4, nrow=2, ncol=4, byrow=TRUE) # Fill across rows instead of down columns) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 1 2 3 4 &gt; matrix(1:4, nrow=1, ncol=5) # Throws an warning because can&#39;t recycle the input data an even number of time ## Warning in matrix(1:4, nrow = 1, ncol = 5): data length [4] is not a sub- ## multiple or multiple of the number of columns [5] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 3 4 1 1.3.2 Matrix dimensions: dim(), nrow() and ncol() These are just quick functions to get the size of a matrix or data frame. &gt; mymatrix = matrix(1:8, nrow=2) # 2x4 matrix &gt; mymatrix ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 &gt; nrow(mymatrix) # 2 rows ## [1] 2 &gt; ncol(mymatrix) # 4 columns ## [1] 4 &gt; dim(mymatrix) # 2x4 matrix ## [1] 2 4 1.4 Data frames 1.4.1 data.frame() You make a data frame with the data.frame() function, where each argument is a column. If you name the arguments, those become the column names. Note that strings are coerced into factors unless you set stringsAsFactors to FALSE. &gt; df = data.frame(number=1:5, letter=LETTERS[1:5], isred=c(T,F,F,T,F)) # T and F are shortcuts for TRUE and FALSE &gt; df ## number letter isred ## 1 1 A TRUE ## 2 2 B FALSE ## 3 3 C FALSE ## 4 4 D TRUE ## 5 5 E FALSE 1.4.2 dim(), nrow() and ncol() These functions work exactly the same as with matrices, above. 1.4.3 names() The names() function returns the column names of a data frame. &gt; names(df) ## [1] &quot;number&quot; &quot;letter&quot; &quot;isred&quot; 1.5 Lists 1.5.1 list() A list is like a data frame in that it can store multiple objects of different types, but they don’t have to be the same length. Lists can store just about anything, including data frames, other lists, and even functions. length() will give you the number of items in a list. Items inside a list can be accessed with the $ operator or giving the list index in double brackets [[]] &gt; mylist = list(a=1:5, b=c(T,T,F), c=mean, d=list(a=1, b=2:5)) &gt; mylist ## $a ## [1] 1 2 3 4 5 ## ## $b ## [1] TRUE TRUE FALSE ## ## $c ## function (x, ...) ## UseMethod(&quot;mean&quot;) ## &lt;bytecode: 0x26b86b0&gt; ## &lt;environment: namespace:base&gt; ## ## $d ## $d$a ## [1] 1 ## ## $d$b ## [1] 2 3 4 5 &gt; length(mylist) ## [1] 4 &gt; length(mylist$b) # Length of item &#39;b&#39; inside the list ## [1] 3 &gt; length(mylist[[2]]) # Same as above, since b is item 2 ## [1] 3 1.6 Reading and writing data 1.6.1 scan() scan() is the most basic function to read data in. The data must be all of the same type, and you must tell R what that type is by giving it an example. (This is usually done by creating a 0-length vector of the appropriate type, such as character(), integer(), etc.) scan() will treat any whitespace as a separator by default, but you can change this with the ‘sep’ argument. &gt; scan(&#39;data/demo_scan.txt&#39;, what=character()) # Read as character ## [1] &quot;1.0&quot; &quot;2.5&quot; &quot;37.6&quot; &quot;-10.5&quot; &quot;14&quot; &quot;7&quot; &gt; &gt; scan(&#39;data/demo_scan.txt&#39;, what=numeric()) # Read as numeric (default) ## [1] 1.0 2.5 37.6 -10.5 14.0 7.0 1.6.2 read.table() and read.csv() read.table() is the generic function to read in a dataframe. It has a lot of arguments you can tweak depending on the input format. read.csv() is a wrapper function that just sets most of these to be the most common for comma-separated documents. &gt; read.table(&quot;data/demo_read_table.txt&quot;) # space-separated ## V1 V2 V3 ## 1 plot variety yield ## 2 001 GoldenQueen 14.3 ## 3 002 Silverado 16.3 ## 4 003 Bicolor 15.0 ## 5 004 Bodacious 15.1 &gt; &gt; read.table(&quot;data/demo_read_table.csv&quot;) # same, but comma-separated ## V1 ## 1 plot,variety,yield ## 2 001,GoldenQueen,14.3 ## 3 002,Silverado,16.3 ## 4 003,Bicolor,15.0 ## 5 004,Bodacious,15.1 1.6.3 write.table() and write.csv() These are like read.table() and read.csv(), but in reverse: they write a dataframe to a file. &gt; df = data.frame(col1=1:10, col2=LETTERS[1:10]) &gt; write.csv(df, file=&quot;data/demo_write_csv.csv&quot;) 1.7 Boolean expressions Boolean expressions have to do with whether something is TRUE or FALSE. They are very useful for checking our data and especially for filtering out things we don’t want. 1.7.1 Basic comparison operators The basic comparison operators are: &gt; Greater than &gt;= Greater than or equal to &lt; Less than &lt; Less than or equal to == Is equal to != Is not equal to &gt; x = c(1, 2, 3, 4) &gt; &gt; # Which values are greater than 2 &gt; x &gt; 2 ## [1] FALSE FALSE TRUE TRUE &gt; &gt; # Same, but now greater-than-or-equal-to &gt; x &gt;= 2 ## [1] FALSE TRUE TRUE TRUE &gt; &gt; # Testing equality &gt; x == 3 ## [1] FALSE FALSE TRUE FALSE &gt; x != 1 ## [1] FALSE TRUE TRUE TRUE 1.7.2 Missing and non-finite values Missing and non-finite values (NULL, Inf, -Inf) cause issues with normal comparison operators, so there is a special family of functions to deal with them is.na() tests if something is missing is.finite() tests if something is a finite value &gt; x = c(2, NA, Inf) &gt; &gt; # Missing values propagate &gt; x &gt; 2 ## [1] FALSE NA TRUE &gt; &gt; # Doesn&#39;t actually test for missing; instead everything is missing &gt; x == NA ## [1] NA NA NA &gt; &gt; # How to actually test what is missing &gt; is.na(x) ## [1] FALSE TRUE FALSE &gt; &gt; # Tests for finite values &gt; is.finite(x) ## [1] TRUE FALSE FALSE 1.7.3 Boolean operators Often we want to combine Boolean expressions to test based on multiple things at once. We do this with the three Boolean operators: * AND, which uses the operator &amp;&amp; (single value) or &amp; (vector) * OR, which uses the operator || (single value) or | (vector) * This is the “pipe” character, usually located just above the backslash * NOT, which uses the operator ! &gt; x = c(1, 2, 3) &gt; &gt; # Use the vector operator &#39;&amp;&#39; b/c testing each value in the vector (more common) &gt; x &gt;= 1 &amp; x &lt; 3 ## [1] TRUE TRUE FALSE &gt; &gt; # Use &#39;&amp;&amp;&#39; because only one value on each side &gt; sum(x) &lt; 10 &amp;&amp; mean(x) &gt; 0 ## [1] TRUE 1.7.4 Subsetting with boolean expressions One of the most common things we do with Boolean operators is use them to subset our data &gt; x = c(1, 2, 3, NA, 5) &gt; &gt; # All values greater than 2 &gt; x[x&gt;2] ## [1] 3 NA 5 &gt; &gt; # All values that are not missing &gt; x[!is.na(x)] ## [1] 1 2 3 5 Subsetting data frames can be done either by using boolean indexes (like with vectors in the last example) or using the subset() function &gt; berries = read.csv(&#39;data/blueberries.csv&#39;) &gt; &gt; # Subset with boolean index &gt; berries[berries$variety==&#39;Cerulean&#39;,] ## plot variety resistance ## 10 10 Cerulean 4.969730 ## 15 15 Cerulean 3.338443 ## 21 21 Cerulean 1.590397 ## 26 26 Cerulean 6.189447 ## 30 30 Cerulean 3.729126 &gt; &gt; # Same, but with the subset() function &gt; subset(berries, berries$variety == &#39;Cerulean&#39;) ## plot variety resistance ## 10 10 Cerulean 4.969730 ## 15 15 Cerulean 3.338443 ## 21 21 Cerulean 1.590397 ## 26 26 Cerulean 6.189447 ## 30 30 Cerulean 3.729126 1.8 Other utility functions 1.8.1 head() and tail() head() and tail() show you the first/last few bits of a data structure. For vectors and lists, it shows the first/last items; for matrices and dataframes, they show the first/last rows. &gt; df = data.frame(a=1:10, b=LETTERS[1:10]) &gt; head(df) # First rows ## a b ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E ## 6 6 F &gt; tail(df) # Last rows ## a b ## 5 5 E ## 6 6 F ## 7 7 G ## 8 8 H ## 9 9 I ## 10 10 J &gt; head(df$a) # First few elements of column a ## [1] 1 2 3 4 5 6 &gt; head(df$a, n=8)# Specify how many you want to see ## [1] 1 2 3 4 5 6 7 8 1.8.2 str() str() (for “structure”) will show you the structure of an object. This is extremely useful for finding out if your dataframe/list/whatever is actually put together correctly. &gt; # Integer vector &gt; myvector = 1:20 &gt; str(myvector) ## int [1:20] 1 2 3 4 5 6 7 8 9 10 ... &gt; &gt; # Data frame; note it shows the data type of each column &gt; myframe = data.frame(a=1:10, b=LETTERS[1:10]) &gt; str(myframe) ## &#39;data.frame&#39;: 10 obs. of 2 variables: ## $ a: int 1 2 3 4 5 6 7 8 9 10 ## $ b: Factor w/ 10 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 2 3 4 5 6 7 8 9 10 &gt; &gt; # List; also shows the type of each element and even nested sub-elements &gt; mylist = list(1:10, c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;), mean, list(a=1:5, b=LETTERS[1:5])) &gt; str(mylist) ## List of 4 ## $ : int [1:10] 1 2 3 4 5 6 7 8 9 10 ## $ : chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## $ :function (x, ...) ## $ :List of 2 ## ..$ a: int [1:5] 1 2 3 4 5 ## ..$ b: chr [1:5] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ... 1.8.3 paste() paste() is what concatenates (joins) strings together. The sep argument determines what character(s) are put between the elements that are pasted &gt; first = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) &gt; second = c(1,2,3) &gt; third = c(&quot;u&quot;,&quot;g&quot;,&quot;a&quot;) &gt; paste(first, second, sep=&quot;_&quot;) ## [1] &quot;A_1&quot; &quot;B_2&quot; &quot;C_3&quot; paste() is especially useful if you have a data frame where plots have bene numbered “nested” inside fields and you need to make a unique label for each of them. (Similar situations come up when needing to uniquely label whole plots for split-plot designs, or strips for strip-plots.) &gt; # Same data frame where plot numbers are nested within fields &gt; mydata = data.frame(field=c(1,1,2,2), plot=c(1,2,1,2)) &gt; mydata ## field plot ## 1 1 1 ## 2 1 2 ## 3 2 1 ## 4 2 2 &gt; &gt; # First label fields and plots so are obviously factors &gt; mydata$field=paste(&quot;field&quot;, mydata$field, sep=&quot;&quot;) &gt; mydata$plot=paste(&quot;plot&quot;, mydata$plot, sep=&quot;&quot;) &gt; mydata ## field plot ## 1 field1 plot1 ## 2 field1 plot2 ## 3 field2 plot1 ## 4 field2 plot2 &gt; &gt; # Now give each plot a unique ID by pasting the field and plot together &gt; mydata$plotID = paste(mydata$field, mydata$plot, sep=&quot;_&quot;) &gt; mydata ## field plot plotID ## 1 field1 plot1 field1_plot1 ## 2 field1 plot2 field1_plot2 ## 3 field2 plot1 field2_plot1 ## 4 field2 plot2 field2_plot2 "],
["anova.html", "Chapter 2 ANOVA 2.1 aov() 2.2 anova() 2.3 Anova() 2.4 Tukey tests", " Chapter 2 ANOVA ANOVA (ANalysis Of VAriance) is one method we use to determine how much of our results are due to different treatments. R actually has two functions to do ANOVA: aov() is basic ANOVA and will be used here. anova() and Anova() are used in conjunction with linear regression and so is discussed on that page instead. 2.1 aov() The aov() function performs direct ANOVA analysis. It is easiest to have your data in a data frame, with your variables as column names. (See this document for an explanation of R’s formula operators.) &gt; # Example ANOVA of maize yield data &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = aov(yield ~ block + variety, data=mydata) &gt; mymodel ## Call: ## aov(formula = yield ~ block + variety, data = mydata) ## ## Terms: ## block variety Residuals ## Sum of Squares 29.9400 12.5425 9.9125 ## Deg. of Freedom 7 3 21 ## ## Residual standard error: 0.6870399 ## Estimated effects may be unbalanced The basic output of aov() gives you the sums of squares and DOF for each of your effects, but does not calculate the F-statistics and p-values we need to determine significance. For that you need to call summary() on the aov() results: &gt; # &#39;mymodel&#39; is the result of the call to aov(), above &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = aov(yield ~ block + variety, data=mydata) &gt; summary(mymodel) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## block 7 29.940 4.277 9.061 3.74e-05 *** ## variety 3 12.543 4.181 8.857 0.000546 *** ## Residuals 21 9.912 0.472 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.2 anova() anova() is a generic function to perform ANOVA analysis on some sort of fitted model, such as the output from lm(). Its output is very similar to that of aov(), but we prefer using anova() because linear regression is more versatile. anova() can only do Type I sums of squares, so model order matters. &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lm(yield ~ block + variety, data=mydata) &gt; anova(mymodel) ## Analysis of Variance Table ## ## Response: yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## block 7 29.9400 4.2771 9.0613 3.743e-05 *** ## variety 3 12.5425 4.1808 8.8573 0.0005458 *** ## Residuals 21 9.9125 0.4720 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 See the section on lmerTest for how to perform ANOVA on random-effect and mixed-effect linear models. 2.3 Anova() Anova() is part of the car package, and we use it to do Type II and Type III sums-of-squares. Note that you have to change the way R handles contrasts for Type III to run correctly. &gt; # Read in data and fit mdoel &gt; library(car) &gt; bananas = read.csv(&#39;data/bananas.csv&#39;) &gt; mymodel = lm(resistance ~ variety * fungicide, data=bananas) &gt; &gt; # Type II &gt; Anova(mymodel, type=2) ## Anova Table (Type II tests) ## ## Response: resistance ## Sum Sq Df F value Pr(&gt;F) ## variety 16.1644 4 10.3353 1.014e-06 *** ## fungicide 2.4407 2 3.1211 0.04989 * ## variety:fungicide 4.6349 8 1.4817 0.17822 ## Residuals 29.3250 75 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; # Type III &gt; options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;)) # So Type III works right &gt; Anova(mymodel, type=3) ## Anova Table (Type III tests) ## ## Response: resistance ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 101.682 1 260.0554 &lt; 2.2e-16 *** ## variety 7.297 4 4.6654 0.002038 ** ## fungicide 2.830 2 3.6189 0.031594 * ## variety:fungicide 4.635 8 1.4817 0.178217 ## Residuals 29.325 75 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.4 Tukey tests ANOVA can tell you that there is a significant difference among your factor levels somwhere, but cannot tell you where. For that, you need a Tukey Test (Tukey’s Honest Significant Difference test). This is basically a bunch of pairwise t-tests to determine which pair(s) of factor levels are different from each other, with correction for the number of comparisons you’re making. A Tukey test should only be run if your ANOVA indicates there is a significant difference somewhere. There are two methods to do Tukey tests in R. The default TukeyHSD() takes a result from aov() and gives you all pairwise p-values for each factor level. (Note: it does not work on linear regression output from lm(): &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = aov(yield ~ block + variety, data=mydata) &gt; TukeyHSD(mymodel) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = yield ~ block + variety, data = mydata) ## ## $block ## diff lwr upr p adj ## block2-block1 0.850 -0.77947909 2.47947909 0.6574659 ## block3-block1 -1.050 -2.67947909 0.57947909 0.4113645 ## block4-block1 -2.000 -3.62947909 -0.37052091 0.0095724 ## block5-block1 -0.225 -1.85447909 1.40447909 0.9997193 ## block6-block1 1.325 -0.30447909 2.95447909 0.1685496 ## block7-block1 0.050 -1.57947909 1.67947909 1.0000000 ## block8-block1 -0.250 -1.87947909 1.37947909 0.9994400 ## block3-block2 -1.900 -3.52947909 -0.27052091 0.0151276 ## block4-block2 -2.850 -4.47947909 -1.22052091 0.0001830 ## block5-block2 -1.075 -2.70447909 0.55447909 0.3834069 ## block6-block2 0.475 -1.15447909 2.10447909 0.9728357 ## block7-block2 -0.800 -2.42947909 0.82947909 0.7186047 ## block8-block2 -1.100 -2.72947909 0.52947909 0.3565008 ## block4-block3 -0.950 -2.57947909 0.67947909 0.5315240 ## block5-block3 0.825 -0.80447909 2.45447909 0.6883738 ## block6-block3 2.375 0.74552091 4.00447909 0.0016661 ## block7-block3 1.100 -0.52947909 2.72947909 0.3565008 ## block8-block3 0.800 -0.82947909 2.42947909 0.7186047 ## block5-block4 1.775 0.14552091 3.40447909 0.0265304 ## block6-block4 3.325 1.69552091 4.95447909 0.0000217 ## block7-block4 2.050 0.42052091 3.67947909 0.0075991 ## block8-block4 1.750 0.12052091 3.37947909 0.0296337 ## block6-block5 1.550 -0.07947909 3.17947909 0.0698250 ## block7-block5 0.275 -1.35447909 1.90447909 0.9989637 ## block8-block5 -0.025 -1.65447909 1.60447909 1.0000000 ## block7-block6 -1.275 -2.90447909 0.35447909 0.2017310 ## block8-block6 -1.575 -3.20447909 0.05447909 0.0629293 ## block8-block7 -0.300 -1.92947909 1.32947909 0.9981982 ## ## $variety ## diff lwr upr p adj ## DK884-DK417 0.0625 -0.895002939 1.0200029 0.9977921 ## M154-DK417 -0.7375 -1.695002939 0.2200029 0.1711460 ## PH991-DK417 1.0250 0.067497061 1.9825029 0.0330723 ## M154-DK884 -0.8000 -1.757502939 0.1575029 0.1232938 ## PH991-DK884 0.9625 0.004997061 1.9200029 0.0485161 ## PH991-M154 1.7625 0.804997061 2.7200029 0.0002401 More useful output comes from the HSD.test() function in the agricolae package, which will tell you the groupings for a factor. It can also work on the output from lm(). (Note that in boht cases you have to specify which factor you’re interested in): &gt; library(agricolae) &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = aov(yield ~ block + variety, data=mydata) &gt; tukey = HSD.test(mymodel, trt=&#39;variety&#39;) # the &#39;trt&#39; argument specified which factor to compare &gt; tukey # HDS.test() doesn&#39;t print out the result by default, so have to print it out manually ## $statistics ## MSerror Df Mean CV MSD ## 0.4720238 21 6.7375 10.19725 0.9575029 ## ## $parameters ## test name.t ntr StudentizedRange alpha ## Tukey variety 4 3.941878 0.05 ## ## $means ## yield std r Min Max Q25 Q50 Q75 ## DK417 6.6500 1.1928358 8 4.9 8.5 5.725 6.85 7.250 ## DK884 6.7125 1.2540648 8 4.8 9.1 6.000 6.65 7.175 ## M154 5.9125 0.7567553 8 4.5 6.6 5.375 6.30 6.425 ## PH991 7.6750 1.4577380 8 5.4 9.6 6.850 8.10 8.450 ## ## $comparison ## NULL ## ## $groups ## yield groups ## PH991 7.6750 a ## DK884 6.7125 b ## DK417 6.6500 b ## M154 5.9125 b ## ## attr(,&quot;class&quot;) ## [1] &quot;group&quot; &gt; &gt; # HSD.test() also works with linear regression output &gt; mylm = lm(yield ~ block + variety, data=mydata) &gt; HSD.test(mymodel, trt=&#39;variety&#39;)$group ## yield groups ## PH991 7.6750 a ## DK884 6.7125 b ## DK417 6.6500 b ## M154 5.9125 b Although there is a lot of information in the output from HSD.test(), the $groups section is what we usually care about, since that tells us which factor levels are/are not significantly different from each other. Index "],
["linear-regression.html", "Chapter 3 Linear Regression 3.1 lm() 3.2 Random effects and lme4 3.3 lmerTest 3.4 EM-Means", " Chapter 3 Linear Regression Linear regression is the workhorse of statistics both in and out of this class. 3.1 lm() lm() (for “linear model”) is the basic linear regression function. Fitting models is the same as fitting them with aov(), and it is recommended to have all your variables in a single data frame with the variable names as columns. (See this document for an explanation of R’s formula operators.) The summary() function will give you the model coefficients and statistical tests. &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lm(yield ~ block + variety, data=mydata) &gt; summary(mymodel) ## ## Call: ## lm(formula = yield ~ block + variety, data = mydata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0000 -0.4188 0.1000 0.3750 0.9125 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.8125 0.4028 16.912 1.04e-13 *** ## blockblock2 0.8500 0.4858 1.750 0.094779 . ## blockblock3 -1.0500 0.4858 -2.161 0.042369 * ## blockblock4 -2.0000 0.4858 -4.117 0.000491 *** ## blockblock5 -0.2250 0.4858 -0.463 0.648025 ## blockblock6 1.3250 0.4858 2.727 0.012618 * ## blockblock7 0.0500 0.4858 0.103 0.919002 ## blockblock8 -0.2500 0.4858 -0.515 0.612204 ## varietyDK884 0.0625 0.3435 0.182 0.857375 ## varietyM154 -0.7375 0.3435 -2.147 0.043636 * ## varietyPH991 1.0250 0.3435 2.984 0.007079 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.687 on 21 degrees of freedom ## Multiple R-squared: 0.8108, Adjusted R-squared: 0.7207 ## F-statistic: 9 on 10 and 21 DF, p-value: 1.406e-05 See the section on ANOVA for how to do an ANOVA analysis of lm() results. 3.2 Random effects and lme4 The lme4 package lets us make random effect models with the function lmer() (linear mixed effect regression; often pronounced ‘lemur’). Random effects are specified by putting “(1|name)” in the formula, where ‘name’ is your variable name. (Although you can tweak the random effects significantly by changing what else is inside the parentheses, you don’t need to get that advanced for this class.) Random effects are usually put last in the model formula. &gt; library(lme4) ## Loading required package: Matrix &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lmer(yield ~ variety + (1|block), data=mydata) &gt; summary(mymodel) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: yield ~ variety + (1 | block) ## Data: mydata ## ## REML criterion at convergence: 82.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.5799 -0.6446 0.1855 0.5195 1.5489 ## ## Random effects: ## Groups Name Variance Std.Dev. ## block (Intercept) 0.9513 0.9753 ## Residual 0.4720 0.6870 ## Number of obs: 32, groups: block, 8 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 6.6500 0.4218 15.766 ## varietyDK884 0.0625 0.3435 0.182 ## varietyM154 -0.7375 0.3435 -2.147 ## varietyPH991 1.0250 0.3435 2.984 ## ## Correlation of Fixed Effects: ## (Intr) vDK884 vrM154 ## varityDK884 -0.407 ## varietyM154 -0.407 0.500 ## varityPH991 -0.407 0.500 0.500 3.2.1 Extracting BLUEs and BLUPs While coefficients() will get you the BLUEs for a normal lm() model, you want to use fixef() and ranef() to get the fixed (BLUEs) and random (BLUPs) effects of lmer() models &gt; library(lme4) &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lmer(yield ~ variety + (1|block), data=mydata) &gt; fixef(mymodel) # Fixed effects (BLUEs) ## (Intercept) varietyDK884 varietyM154 varietyPH991 ## 6.6500 0.0625 -0.7375 1.0250 &gt; ranef(mymodel) # Random effects (BLUPs) ## $block ## (Intercept) ## block1 0.14456656 ## block2 0.90076090 ## block3 -0.78955585 ## block4 -1.63471422 ## block5 -0.05560252 ## block6 1.32334009 ## block7 0.18904858 ## block8 -0.07784353 ## ## with conditional variances for &quot;block&quot; 3.3 lmerTest Running analyses of lmer() results is much easier with the lmerTest package installed, since it gives you ANOVA functionality on random effects models. &gt; library(lmerTest) # Automatically loads lme4 ## ## Attaching package: &#39;lmerTest&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmer ## The following object is masked from &#39;package:stats&#39;: ## ## step &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lmer(yield ~ variety + (1|block), data=mydata) &gt; # ANOVA of fixed effects &gt; anova(mymodel) ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## variety 12.543 4.1808 3 21 8.8573 0.0005458 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; # ANOVA-like analysis of random effects &gt; ranova(mymodel) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## yield ~ variety + (1 | block) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 6 -41.093 94.186 ## (1 | block) 5 -48.831 107.662 15.476 1 8.357e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.4 EM-Means Estimated Marginal Means are basically the best estimate of the main effect of a model when it’s averaged over all levels of other effects. (So, for example, the best estimate of each plant variety averaged over blocks, years, etc.) They are especially useful when some of your treatments don’t appear in every block because they help remove the bias that can cause. EM-Means are calculated with the emmeans package using the emmeans() function. &gt; library(emmeans) &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lm(yield ~ block + variety, data=mydata) &gt; emmeans(mymodel, specs=&quot;variety&quot;) # Specs specifies which terms you&#39;re looking at ## variety emmean SE df lower.CL upper.CL ## DK417 6.65 0.243 21 6.14 7.16 ## DK884 6.71 0.243 21 6.21 7.22 ## M154 5.91 0.243 21 5.41 6.42 ## PH991 7.67 0.243 21 7.17 8.18 ## ## Results are averaged over the levels of: block ## Confidence level used: 0.95 3.4.1 CLD() To perform a Tukey-like test and get a compact letter distplay of the results, use CLD() &gt; library(emmeans) &gt; mydata = read.csv(&#39;data/maize.csv&#39;) &gt; mymodel = lm(yield ~ block + variety, data=mydata) &gt; mymeans = emmeans(mymodel, specs=&quot;variety&quot;) &gt; CLD(mymeans) ## Warning: &#39;CLD&#39; will be deprecated. Its use is discouraged. ## See &#39;? CLD&#39; for an explanation. Use &#39;pwpp&#39; or &#39;multcomp::cld&#39; instead. ## variety emmean SE df lower.CL upper.CL .group ## M154 5.91 0.243 21 5.41 6.42 1 ## DK417 6.65 0.243 21 6.14 7.16 1 ## DK884 6.71 0.243 21 6.21 7.22 1 ## PH991 7.67 0.243 21 7.17 8.18 2 ## ## Results are averaged over the levels of: block ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 4 estimates ## significance level used: alpha = 0.05 "],
["experimental-designs.html", "Chapter 4 Experimental Designs 4.1 Factorial designs 4.2 Completely randomized design 4.3 Randomized complete block designs 4.4 Latin Squares 4.5 Graeco-Latin Squares 4.6 Balanced Incomplete Block Designs 4.7 Confounded designs 4.8 Split-plot designs 4.9 Strip-plot designs 4.10 Augmented designs", " Chapter 4 Experimental Designs These are the various designs we have covered in class, with quick notes about how to create them and how to analyze them. This is meant to be a quick cheat-sheet; for a full explanation, see the lecture notes. Most of these designs can be created using the agricolae package. The output from agricolae’s design.____() family of functions has a lot of useful information, but the part you’re probably most interested in are the $book and $sketch parts, which have a data table and field layout of the experiment. (Not all designs generate a $sketch component.) Note on randomization: Remember to use set.seed() to set your random seed before randomizing your design. This will let you recreate it in case something ever goes wrong. Just be sure to use a different random seed if you need a different randomization (e.g., doing the same experiment the next year.) 4.1 Factorial designs Factorial designs aren’t really a separate design, since ‘factorial’ just means you’re making all possible combinations of two (or more) treatments. As such, any design can be a factorial design. Just make sure you put all your treatments (and any interactions you’re interested in) into your models. 4.2 Completely randomized design CRDs are the simplest design where you just have replicates of your treatments arranged randomly in your experiment. You can make a CRD in basic R using the rep() and sample() functions to replicate and randomize your samples, respectively. &gt; treatments=LETTERS[1:10] # Define treatments &gt; design = rep(treatments, 3) # 3 replicates of each treatment &gt; design = sample(design, replace=F) # By default, sample() will make a sample the same size as what you give it &gt; design ## [1] &quot;B&quot; &quot;A&quot; &quot;D&quot; &quot;D&quot; &quot;G&quot; &quot;J&quot; &quot;I&quot; &quot;C&quot; &quot;A&quot; &quot;I&quot; &quot;J&quot; &quot;F&quot; &quot;D&quot; &quot;H&quot; &quot;J&quot; &quot;H&quot; &quot;B&quot; &quot;F&quot; &quot;I&quot; ## [20] &quot;F&quot; &quot;B&quot; &quot;E&quot; &quot;G&quot; &quot;E&quot; &quot;E&quot; &quot;A&quot; &quot;C&quot; &quot;H&quot; &quot;C&quot; &quot;G&quot; You can also use design.crd() from agricolae to do the same thing &gt; library(agricolae) &gt; treatments=LETTERS[1:10] # Define treatments &gt; design = design.crd(trt=treatments, r=3) # 3 replicates of each treatment &gt; head(design$book) # Fieldbook data (only first few lines shown) ## plots r treatments ## 1 101 1 D ## 2 102 1 A ## 3 103 2 A ## 4 104 1 I ## 5 105 1 E ## 6 106 1 H Since CRDs only involve your treatments, there are no special considerations to analyze them by ANOVA or Linear Regression. &gt; berries=read.csv(&#39;data/blueberries.csv&#39;) &gt; mymodel = lm(resistance ~ variety, data=berries) &gt; anova(mymodel) ## Analysis of Variance Table ## ## Response: resistance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## variety 5 45.99 9.1980 4.4804 0.00503 ** ## Residuals 24 49.27 2.0529 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.3 Randomized complete block designs RCBDs are the workhorses of experimental design. They’re probably the most common overall, and you should probably start with them as your default design and change to something else only if there’s a reason RCBD won’t work. While you can make your own RCBD using basic R, it’s much easier to let agricolae do it for you &gt; library(agricolae) &gt; treatments=LETTERS[1:10] # Define treatments &gt; design = design.rcbd(trt=treatments, r=3) # 3 replicates of each treatment &gt; design$sketch # Field layout ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] &quot;J&quot; &quot;H&quot; &quot;F&quot; &quot;B&quot; &quot;A&quot; &quot;D&quot; &quot;I&quot; &quot;G&quot; &quot;E&quot; &quot;C&quot; ## [2,] &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;J&quot; &quot;B&quot; &quot;F&quot; &quot;H&quot; &quot;A&quot; &quot;I&quot; &quot;G&quot; ## [3,] &quot;H&quot; &quot;I&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;B&quot; &quot;G&quot; &quot;A&quot; &quot;F&quot; &quot;J&quot; &gt; head(design$book) # Fieldbook data (only first few lines shown) ## plots block treatments ## 1 101 1 J ## 2 102 1 H ## 3 103 1 F ## 4 104 1 B ## 5 105 1 A ## 6 106 1 D When analyzing RCBDs, make sure to include your block term. If you’re using a fixed-effects model (meaning lm()), blocks should go first in your model because they’re a nuisance variable. If using a mixed-effects model, blocks are usually treated as random effects because we don’t care about the specific blocks you used. &gt; # Factorial analysis of bananas &gt; bananas = read.csv(&#39;data/bananas.csv&#39;) &gt; &gt; # Fixed effects model &gt; fixed = lm(resistance ~ block + variety * fungicide, data=bananas) &gt; anova(fixed) ## Analysis of Variance Table ## ## Response: resistance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## block 5 9.5397 1.9079 6.7502 3.462e-05 *** ## variety 4 16.1644 4.0411 14.2973 1.401e-08 *** ## fungicide 2 2.4407 1.2203 4.3175 0.01706 * ## variety:fungicide 8 4.6349 0.5794 2.0498 0.05276 . ## Residuals 70 19.7853 0.2826 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; # Mixed effects model &gt; library(lmerTest) ## Loading required package: lme4 ## Loading required package: Matrix ## ## Attaching package: &#39;lmerTest&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmer ## The following object is masked from &#39;package:stats&#39;: ## ## step &gt; mixed = lmer(resistance ~ (1|block) + variety * fungicide, data=bananas) &gt; &gt; # ANOVA of fixed effects &gt; anova(mixed) ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## variety 16.1644 4.0411 4 70 14.2973 1.401e-08 *** ## fungicide 2.4407 1.2203 2 70 4.3175 0.01706 * ## variety:fungicide 4.6349 0.5794 8 70 2.0498 0.05276 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; # Similar analysis of random effects &gt; ranova(mixed) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## resistance ~ variety + fungicide + (1 | block) + variety:fungicide ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 17 -77.249 188.50 ## (1 | block) 16 -84.644 201.29 14.79 1 0.0001202 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.4 Latin Squares Latin squares involve comparing several treatments that all have the same number of levels. While you can do this on your own, it’s much easier to let agricolae do it for you. &gt; library(agricolae) &gt; treatments=LETTERS[1:4] &gt; design=design.lsd(trt=treatments) # Only have to supply the treatment levels &gt; design$sketch # Field layout ## [,1] [,2] [,3] [,4] ## [1,] &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;A&quot; ## [2,] &quot;C&quot; &quot;D&quot; &quot;A&quot; &quot;B&quot; ## [3,] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ## [4,] &quot;D&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &gt; head(design$book) # Fieldbook data (only first few lines shown) ## plots row col treatments ## 1 101 1 1 B ## 2 102 1 2 C ## 3 103 1 3 D ## 4 104 1 4 A ## 5 201 2 1 C ## 6 202 2 2 D Since pairwise interactions only occur once in a Latin Square, you can only test main effects, not interactions &gt; clover = read.csv(&quot;data/clover.csv&quot;) &gt; mymodel = lm(biomass ~ location + scorer + variety, data=clover) &gt; anova(mymodel) ## Analysis of Variance Table ## ## Response: biomass ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## location 4 46.86 11.716 6.1434 0.006277 ** ## scorer 4 19.41 4.853 2.5450 0.094148 . ## variety 4 348.51 87.127 45.6870 3.629e-07 *** ## Residuals 12 22.88 1.907 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.5 Graeco-Latin Squares Graeco-Latin squares are just Latin Squares with an extra main effect added on, so that all pairwise combinations still occur once. Although in theory you can layer these many layers deep (with 6, 7, 8, etc. effects you’re testing), in practice you really don’t want to go deeper than four (row, column, treatment 1, treatment 2). Probably for this reason, agricolae only does the most basic Graeco-Latin Square: &gt; library(agricolae) &gt; treat1=LETTERS[1:4] &gt; treat2=LETTERS[5:8] &gt; design=design.graeco(trt1=treat1, trt2=treat2) &gt; design$sketch # Field layout ## [,1] [,2] [,3] [,4] ## [1,] &quot;D F&quot; &quot;C E&quot; &quot;A H&quot; &quot;B G&quot; ## [2,] &quot;C H&quot; &quot;D G&quot; &quot;B F&quot; &quot;A E&quot; ## [3,] &quot;A G&quot; &quot;B H&quot; &quot;D E&quot; &quot;C F&quot; ## [4,] &quot;B E&quot; &quot;A F&quot; &quot;C G&quot; &quot;D H&quot; &gt; head(design$book) # Fieldbook data (only first few lines shown) ## plots row col treat1 treat2 ## 1 101 1 1 D F ## 2 102 1 2 C E ## 3 103 1 3 A H ## 4 104 1 4 B G ## 5 201 2 1 C H ## 6 202 2 2 D G Analysis of Graeco-Latin squares is identical to Latin Squares, with the only real constraint being that you can only test main effects, not interactions. 4.6 Balanced Incomplete Block Designs BIBD can be easily constructed in agricolae, assuming the parameters you’ve chosen are compatible. (Not all combinations of treatment levels, reps, and block size can actually give a working BIBD.) &gt; # Make a basic BIBD &gt; library(agricolae) &gt; treatments = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;) &gt; bibd = design.bib(trt=treatments, k=3) # R will find smallest # of reps that works ## ## Parameters BIB ## ============== ## Lambda : 2 ## treatmeans : 4 ## Block size : 3 ## Blocks : 4 ## Replication: 3 ## ## Efficiency factor 0.8888889 ## ## &lt;&lt;&lt; Book &gt;&gt;&gt; &gt; bibd$sketch # Check layout ## [,1] [,2] [,3] ## [1,] &quot;A&quot; &quot;D&quot; &quot;C&quot; ## [2,] &quot;C&quot; &quot;A&quot; &quot;B&quot; ## [3,] &quot;A&quot; &quot;B&quot; &quot;D&quot; ## [4,] &quot;D&quot; &quot;C&quot; &quot;B&quot; &gt; bibd$book # Fieldbook table ## plots block treatments ## 1 101 1 A ## 2 102 1 D ## 3 103 1 C ## 4 201 2 C ## 5 202 2 A ## 6 203 2 B ## 7 301 3 A ## 8 302 3 B ## 9 303 3 D ## 10 401 4 D ## 11 402 4 C ## 12 403 4 B &gt; &gt; &gt; # Wrong number of reps &gt; design.bib(trt=LETTERS[1:8], k=4, r=3) ## ## Change r by 7, 14 ... &gt; # Poor value of k &gt; design.bib(trt=LETTERS[1:8], k=6, r=3) ## Other k &lt;&gt; 6 ; 1&lt;k&lt; 8 &gt; # Just plain error &gt; design.bib(trt=LETTERS[1:8], k=5) ## Error in rep(k, b): invalid &#39;times&#39; argument Analyzing a BIBD is pretty straightforward to analyze, since it’s just an experiment parcelled out into incomplete blocks. &gt; onions = read.csv(&quot;data/onions.csv&quot;) &gt; mymodel = lm(disease ~ block + variety, data=onions) &gt; anova(mymodel) ## Analysis of Variance Table ## ## Response: disease ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## block 9 7.1787 0.79763 2.1811 0.08318 . ## variety 4 4.5489 1.13722 3.1098 0.04516 * ## Residuals 16 5.8511 0.36569 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.7 Confounded designs Building a confounded design requires a little work with the conf.design package. It’s kind of tricky because you have to specify which things are confounded, then do the replication and randomization yourself. You won’t need to make your own confounded designs in this class for that reason. Analyzing a confounded design, however, is straightforward and follows the same pattern as RCBD, BIBD, Latin Squares, etc. Just be aware that you won’t be able to test whatever effect(s) you confounded (unless it’s only a partially confounded design). &gt; mydata = read.csv(&quot;data/confounded.csv&quot;) &gt; mymodel = lm(disease ~ covercrop * solarize, data=mydata) &gt; anova(mymodel) ## Analysis of Variance Table ## ## Response: disease ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## covercrop 1 14.098 14.098 2.1248 0.21867 ## solarize 1 79.758 79.758 12.0209 0.02565 * ## covercrop:solarize 1 46.465 46.465 7.0030 0.05720 . ## Residuals 4 26.540 6.635 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.8 Split-plot designs Split-plot designs involve using one of your main effects as a blocking factor, usually because it’s hard to change. Split-plots can be generated in agricolae by specifying the two treatments, number of reps, and the design for the whole plots &gt; library(agricolae) &gt; wholeplot=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) &gt; subplot=c(&quot;test1&quot;, &quot;test2&quot;, &quot;test3&quot;,&quot;test4&quot;, &quot;test5&quot;) &gt; # Make a design with whole plots in RCBD with 3 reps &gt; mydesign = design.split(trt1=wholeplot, trt2=subplot, r=3, design=&#39;rcbd&#39;) &gt; head(mydesign$book) ## plots splots block wholeplot subplot ## 1 101 1 1 A test1 ## 2 101 2 1 A test2 ## 3 101 3 1 A test4 ## 4 101 4 1 A test3 ## 5 101 5 1 A test5 ## 6 102 1 1 C test1 Since all the measurements within each whole-plot are correlated with each other, we need to account for that in our analyses. Although you can specify additional error terms with aov(), it’s easier to just use random effects and lme4 with lmer(). Note: Make sure each unique whole-plot has a unique label so that they are treated correctly. &gt; library(lmerTest) &gt; mydata = read.csv(&#39;data/splitplot.csv&#39;) # CRD, so no block effect &gt; mymodel = lmer(yield ~ fertilizer * variety + (1|wholeplot), data=mydata) ## boundary (singular) fit: see ?isSingular &gt; anova(mymodel) # Fixed effect ANOVA ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## fertilizer 452.40 452.40 1 16 343.5962 3.078e-12 *** ## variety 159.38 53.13 3 16 40.3494 1.091e-07 *** ## fertilizer:variety 17.13 5.71 3 16 4.3354 0.0204 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; ranova(mymodel) # Random effect test (similar to ANOVA) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## yield ~ fertilizer + variety + (1 | wholeplot) + fertilizer:variety ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 10 -29.298 78.597 ## (1 | wholeplot) 9 -29.298 76.597 -7.1054e-15 1 1 If the whole-plots are in a RCBD design, make sure to include the blocks in the model as well. &gt; library(lmerTest) &gt; mydata = read.csv(&#39;data/splitplot_rcbd.csv&#39;) &gt; mymodel = lmer(yield ~ fertilizer * variety + (1|block) + (1|wholeplot), data=mydata) &gt; anova(mymodel) # Fixed effect ANOVA ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## fertilizer 224.97 112.487 2 4 104.1275 0.0003551 *** ## variety 500.88 125.221 4 24 115.9153 2.505e-15 *** ## fertilizer:variety 43.67 5.459 8 24 5.0536 0.0009221 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; ranova(mymodel) # Random effect test (similar to ANOVA) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## yield ~ fertilizer + variety + (1 | block) + (1 | wholeplot) + ## fertilizer:variety ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 18 -56.944 149.89 ## (1 | block) 17 -59.320 152.64 4.7522 1 0.02926 * ## (1 | wholeplot) 17 -57.570 149.14 1.2508 1 0.26340 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.9 Strip-plot designs Strip-plots are almost identical to split-splots, except you have two whole-plot random effects (one for each strip), plus another one for blocks if they are arranged in RCBD (which they usually are). &gt; library(lmerTest) &gt; mydata = read.csv(&#39;data/strip_plot.csv&#39;) &gt; mymodel = lmer(disease ~ fertilizer * irrigation + (1|block) + (1|strip1) + (1|strip2), data=mydata) ## boundary (singular) fit: see ?isSingular &gt; anova(mymodel) # Fixed effect ANOVA ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## fertilizer 118.827 59.414 2 6.8856 6.9135 0.02256 * ## irrigation 43.898 21.949 2 7.5786 2.5541 0.14194 ## fertilizer:irrigation 87.991 21.998 4 11.8864 2.5597 0.09341 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; ranova(mymodel) # Random effect test (similar to ANOVA) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## disease ~ fertilizer + irrigation + (1 | block) + (1 | strip1) + ## (1 | strip2) + fertilizer:irrigation ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 13 -82.829 191.66 ## (1 | block) 12 -82.829 189.66 0.0000 1 1.00000 ## (1 | strip1) 12 -83.864 191.73 2.0714 1 0.15008 ## (1 | strip2) 12 -84.804 193.61 3.9517 1 0.04682 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.10 Augmented designs "],
["plotting-tools.html", "Chapter 5 Plotting Tools 5.1 Scatterplots 5.2 Histograms 5.3 Boxplots 5.4 Violin plots", " Chapter 5 Plotting Tools 5.1 Scatterplots 5.2 Histograms 5.3 Boxplots 5.4 Violin plots "]
]
